{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 匯入相關所需的模組\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import h5py\n",
    "import glob\n",
    "import time\n",
    "from random import shuffle\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint ,EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_set'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#印出目前工作目錄\n",
    "#print(os.getcwd())  \n",
    "imgsPath ='./training_set'\n",
    "mappingPath ='classmap.csv'\n",
    "imgsPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'rika', 1: 'risa', 2: 'yui', 3: 'akane', 4: 'neru'}\n"
     ]
    }
   ],
   "source": [
    "# Map File Read\n",
    "map_characters ={}\n",
    "\n",
    "with open(mappingPath) as pf:\n",
    "    for line in pf:\n",
    "        (key, val) = line.split(',')\n",
    "        #map_characters[key] = int(val)\n",
    "        #print(key,val)\n",
    "        if key == 'classname':\n",
    "            continue\n",
    "        map_characters[int(val)] = key\n",
    "        \n",
    "        \n",
    "print(map_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 224\n",
    "img_height = 224\n",
    "\n",
    "num_classes = len(map_characters) # 要辨識的角色種類\n",
    "\n",
    "#pictures_per_class = 1000 # 每個角色會有接近1000張訓練圖像\n",
    "test_size = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將訓練資料圖像從檔案系統中取出並進行\n",
    "def load_pictures():\n",
    "    pics = []\n",
    "    labels = []\n",
    "    \n",
    "    for k, v in map_characters.items(): # k: 數字編碼 v: 角色label\n",
    "        # 把某一個角色在檔案夾裡的所有圖像檔的路徑捉出來\n",
    "        #print(imgsPath + \"/\" + v + \"/*.png\")\n",
    "        pictures = [k for k in glob.glob(imgsPath + \"/\" + v + \"/*.png\")]        \n",
    "        print(v + \" : \" + str(len(pictures))) # 看一下每個角色有多少訓練圖像\n",
    "        for i, pic in enumerate(pictures):\n",
    "            tmp_img = cv2.imread(pic)  # to gray\n",
    "           \n",
    "            # 由於OpenCv讀圖像時是以BGR (Blue-Green-Red), 我們把它轉置成RGB (Red-Green-Blue)\n",
    "            tmp_img = cv2.cvtColor(tmp_img, cv2.COLOR_BGR2RGB)\n",
    "            #tmp_img = cv2.cvtColor(tmp_img, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            tmp_img = cv2.resize(tmp_img, (img_height, img_width )) # 進行大小歸一位  \n",
    "            #tmp_img = np.expand_dims(tmp_img, axis=2) #增加一個維度\n",
    "            \n",
    "            pics.append(tmp_img)\n",
    "            labels.append(k)    \n",
    "    return np.array(pics), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得訓練資料集與驗證資料集\n",
    "def get_dataset(save=False, load=False):\n",
    "    if load: \n",
    "        # 從檔案系統中載入之前處理保存的訓練資料集與驗證資料集\n",
    "        h5f = h5py.File('dataset.h5','r')\n",
    "        X_train = h5f['X_train'][:]\n",
    "        X_test = h5f['X_test'][:]\n",
    "        h5f.close()\n",
    "        \n",
    "        # 從檔案系統中載入之前處理保存的訓練資料標籤與驗證資料集籤\n",
    "        h5f = h5py.File('labels.h5', 'r')\n",
    "        y_train = h5f['y_train'][:]\n",
    "        y_test = h5f['y_test'][:]\n",
    "        h5f.close()\n",
    "    else:\n",
    "        # 從最原始的圖像檔案開始處理\n",
    "        X, y = load_pictures()\n",
    "        y = keras.utils.to_categorical(y, num_classes) # 目標的類別種類數\n",
    "        \n",
    "        # 將資料切分為訓練資料集與驗證資料集 (85% vs. 15%)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size ,shuffle = 'true') \n",
    "        if save: # 保存尚未進行歸一化的圖像數據\n",
    "            h5f = h5py.File('dataset.h5', 'w')\n",
    "            h5f.create_dataset('X_train', data=X_train)\n",
    "            h5f.create_dataset('X_test', data=X_test)\n",
    "            h5f.close()\n",
    "            \n",
    "            h5f = h5py.File('labels.h5', 'w')\n",
    "            h5f.create_dataset('y_train', data=y_train)\n",
    "            h5f.create_dataset('y_test', data=y_test)\n",
    "            h5f.close()\n",
    "    \n",
    "    # 進行圖像每個像素值的型別轉換與歸一化處理\n",
    "    X_train = X_train.astype('float32') / 255.\n",
    "    X_test = X_test.astype('float32') / 255.\n",
    "    print(\"Train\", X_train.shape, y_train.shape)\n",
    "    print(\"Test\", X_test.shape, y_test.shape)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rika : 100\n",
      "risa : 102\n",
      "yui : 114\n",
      "akane : 107\n",
      "neru : 115\n",
      "Train (430, 224, 224, 3) (430, 5)\n",
      "Test (108, 224, 224, 3) (108, 5)\n"
     ]
    }
   ],
   "source": [
    "# 取得訓練資料集與驗證資料集  \n",
    "X_train, X_test, y_train, y_test = get_dataset(save=True, load=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\envs\\AIA-1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\envs\\AIA-1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\envs\\AIA-1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\envs\\AIA-1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\envs\\AIA-1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\envs\\AIA-1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\envs\\AIA-1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\envs\\AIA-1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 3 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 3 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 3 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 3 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 3 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 6 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 6 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 6 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 8 5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 8 240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 8 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 1 138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 1 576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 1 0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 6 192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 6 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 4 9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 9 55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 4 144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 9 288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 4 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 9 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, None, None, 1 0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 6 76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 9 82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 3 6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 6 192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 6 192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 9 288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 3 96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 9 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None, 3 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, None, None, 2 0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 6 192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, None, 6 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 4 12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 9 55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 4 144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, None, 9 288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 4 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, None, 9 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, None, None, 2 0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 6 76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 9 82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 6 16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 6 192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 6 192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, None, 9 288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, None, 6 192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, None, 6 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, None, 6 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, None, 9 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, None, None, 6 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, None, None, 2 0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, None, 6 192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, None, 6 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 4 13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 9 55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, None, 4 144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 9 288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, None, 4 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, None, 9 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, None, None, 2 0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 6 76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 9 82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 6 18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, None, 6 192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, None, 6 192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 9 288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 6 192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, None, None, 6 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, None, 6 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, None, 9 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, None, 6 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, None, None, 2 0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 6 18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, None, 6 192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, None, 6 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 9 55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, None, 9 288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, None, 9 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 3 995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, None, None, 9 82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, None, 3 1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, None, 9 288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, None, 3 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, None, 9 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 2 0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, None, None, 7 0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, None, 1 384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, None, 1 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, None, None, 1 114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 1 384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, None, 1 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, None, None, 1 114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 1 384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, None, 1 384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, None, None, 1 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, None, 1 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, None, None, 1 114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, None, None, 1 114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 1 384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, None, 1 384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, None, None, 1 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, None, 1 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, None, None, 7 0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, None, None, 1 147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, None, None, 1 172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, None, None, 1 172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 1 576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 1 576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, None, 1 576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, None, 1 576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, None, None, 1 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, None, None, 1 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, None, 1 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, None, 1 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, None, None, 7 0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, None, None, 1 480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, None, 1 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, None, None, 1 179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, None, None, 1 480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, None, 1 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, None, None, 1 179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, None, None, 1 480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, None, None, 1 480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, None, 1 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, None, 1 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, None, None, 1 179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, None, None, 1 179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, None, None, 1 480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, None, None, 1 480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, None, 1 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, None, 1 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, None, None, 7 0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, None, None, 1 147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, None, None, 1 215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, None, None, 1 215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, None, None, 1 576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, None, None, 1 576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, None, None, 1 576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, None, None, 1 576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 1 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, None, 1 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, None, None, 7 0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, None, None, 1 480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, None, None, 1 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, None, None, 1 179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, None, None, 1 480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, None, None, 1 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, None, None, 1 179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, None, 1 480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, None, None, 1 480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, None, None, 1 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, None, None, 1 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, None, None, 1 179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, None, None, 1 179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, None, 1 480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, None, None, 1 480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, None, None, 1 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, None, None, 1 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, None, None, 7 0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, None, None, 1 147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, None, None, 1 215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, None, None, 1 215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, None, None, 1 576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, None, None, 1 576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, None, None, 1 576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, None, None, 1 576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, None, 1 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, None, None, 1 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, None, None, 1 0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, None, None, 1 0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, None, None, 7 0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, None, None, 1 576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, None, 1 0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, None, None, 1 258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, None, None, 1 576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, None, None, 1 0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, None, None, 1 258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, None, None, 1 576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, None, None, 1 576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, None, None, 1 0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, None, None, 1 0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, None, None, 1 258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, None, None, 1 258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, None, None, 1 576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, None, None, 1 576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, None, 1 0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, None, None, 1 0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, None, None, 7 0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, None, None, 1 258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, None, None, 1 258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, None, None, 1 576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, None, None, 1 576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, None, None, 1 576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, None, None, 1 576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, None, None, 1 0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, None, 1 0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, None, None, 1 0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, None, None, 1 0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, None, None, 7 0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, None, None, 1 576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, None, None, 1 0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, None, None, 1 258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, None, None, 1 576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, None, None, 1 0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, None, None, 1 258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, None, None, 1 576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, None, None, 1 576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, None, None, 1 0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, None, None, 1 0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, None, None, 3 552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, None, None, 1 331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, None, None, 3 960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, None, None, 1 576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, None, None, 3 0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, None, None, 1 0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, None, None, 7 0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, None, None, 1 0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, None, None, 4 573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, None, None, 4 1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, None, None, 4 0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, None, None, 3 491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, None, None, 3 1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, None, None, 3 1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, None, None, 3 1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, None, None, 3 0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, None, None, 3 0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, None, None, 1 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, None, None, 3 409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, None, None, 3 1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, None, None, 3 1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, None, None, 3 1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, None, None, 3 1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, None, None, 1 245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, None, None, 3 960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, None, None, 3 0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, None, None, 3 0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, None, None, 3 0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, None, None, 3 0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, None, None, 1 576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, None, None, 3 0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 7 0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, None, None, 1 0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, None, None, 2 0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, None, None, 4 917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, None, None, 4 1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, None, None, 4 0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, None, None, 3 786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, None, None, 3 1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, None, None, 3 1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, None, None, 3 1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, None, None, 3 0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, None, None, 3 0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, None, None, 2 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, None, None, 3 655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, None, None, 3 1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, None, None, 3 1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, None, None, 3 1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, None, None, 3 1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, None, None, 1 393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, None, None, 3 960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, None, None, 3 0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, None, None, 3 0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, None, None, 3 0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, None, None, 3 0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, None, None, 1 576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, None, None, 3 0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 7 0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, None, None, 1 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, None, None, 2 0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 5)            5125        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,906,085\n",
      "Trainable params: 23,871,653\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "def create_model_six_conv(input_shape):\n",
    "     \n",
    "        '''model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(32, (3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        \n",
    "        model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "        model.add(Dense(128))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "      \n",
    "        model.add(Dense(num_classes, activation='sigmoid'))     \n",
    "        '''\n",
    "       \n",
    "\n",
    "        # create the base pre-trained model\n",
    "        base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "        # add a global spatial average pooling layer\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        # let's add a fully-connected layer\n",
    "        x = Dense(1024, activation='relu')(x)\n",
    "        # and a logistic layer -- let's say we have 200 classes\n",
    "        predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "        # this is the model we will train\n",
    "        model = Model(inputs=base_model.input, outputs=predictions)\n",
    "        \n",
    "        return model;\n",
    "        \n",
    "    \n",
    "#圖像的shape是 (42,42,3)\n",
    "model = create_model_six_conv((img_height, img_width, 3)) # 初始化一個模型\n",
    "\n",
    "\n",
    "\n",
    "model.summary() # 秀出模型架構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False   # randomly flip images\n",
    "            )  \n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "\n",
    "# 保存在訓練過程中比較好的模型\n",
    "filepath=\"model-dtaug.h5\"\n",
    "\n",
    "# 保留\"val_acc\"最好的那個模型\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\envs\\AIA-1\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nlr = 0.001\\nAdam=keras.optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\\nmodel.compile(loss='categorical_crossentropy',\\n             optimizer=Adam,\\n             metrics=['accuracy'])\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 讓我們先配置一個常用的組合來作為後續優化的基準點\n",
    "lr = 0.01\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=sgd,\n",
    "             metrics=['accuracy'])\n",
    "'''\n",
    "lr = 0.001\n",
    "Adam=keras.optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=Adam,\n",
    "             metrics=['accuracy'])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\envs\\AIA-1\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/50\n",
      "Learning Rete :0.01\n",
      "40/40 [==============================] - 19s 476ms/step - loss: 1.0516 - acc: 0.5887 - val_loss: 1.7881 - val_acc: 0.4537\n",
      "Epoch 2/50\n",
      "Learning Rete :0.01\n",
      "40/40 [==============================] - 8s 188ms/step - loss: 0.5115 - acc: 0.8134 - val_loss: 2.5842 - val_acc: 0.2593\n",
      "Epoch 3/50\n",
      "Learning Rete :0.01\n",
      "40/40 [==============================] - 10s 246ms/step - loss: 0.3617 - acc: 0.8731 - val_loss: 3.4934 - val_acc: 0.3426\n",
      "Epoch 4/50\n",
      "Learning Rete :0.01\n",
      "40/40 [==============================] - 10s 245ms/step - loss: 0.2194 - acc: 0.9300 - val_loss: 4.2653 - val_acc: 0.3426\n",
      "Epoch 5/50\n",
      "Learning Rete :0.01\n",
      "40/40 [==============================] - 10s 245ms/step - loss: 0.2013 - acc: 0.9276 - val_loss: 2.6380 - val_acc: 0.4630\n",
      "Epoch 6/50\n",
      "Learning Rete :0.01\n",
      "40/40 [==============================] - 10s 238ms/step - loss: 0.1199 - acc: 0.9597 - val_loss: 1.4891 - val_acc: 0.6667\n",
      "Epoch 7/50\n",
      "Learning Rete :0.01\n",
      "40/40 [==============================] - 10s 246ms/step - loss: 0.1678 - acc: 0.9482 - val_loss: 4.4357 - val_acc: 0.4167\n",
      "Epoch 8/50\n",
      "Learning Rete :0.01\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 0.1410 - acc: 0.9527 - val_loss: 1.8686 - val_acc: 0.5648\n",
      "Epoch 9/50\n",
      "Learning Rete :0.01\n",
      "40/40 [==============================] - 10s 247ms/step - loss: 0.0627 - acc: 0.9836 - val_loss: 2.2520 - val_acc: 0.5185\n",
      "Epoch 10/50\n",
      "Learning Rete :0.01\n",
      "40/40 [==============================] - 10s 245ms/step - loss: 0.0740 - acc: 0.9722 - val_loss: 1.9381 - val_acc: 0.5556\n",
      "Epoch 11/50\n",
      "Learning Rete :0.001\n",
      "40/40 [==============================] - 10s 247ms/step - loss: 0.0745 - acc: 0.9742 - val_loss: 1.4740 - val_acc: 0.6574\n",
      "Epoch 12/50\n",
      "Learning Rete :0.001\n",
      "40/40 [==============================] - 10s 244ms/step - loss: 0.0448 - acc: 0.9857 - val_loss: 1.3059 - val_acc: 0.6759\n",
      "Epoch 13/50\n",
      "Learning Rete :0.001\n",
      "40/40 [==============================] - 10s 242ms/step - loss: 0.0307 - acc: 0.9894 - val_loss: 1.0372 - val_acc: 0.7037\n",
      "Epoch 14/50\n",
      "Learning Rete :0.001\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 0.0204 - acc: 0.9937 - val_loss: 0.9398 - val_acc: 0.7222\n",
      "Epoch 15/50\n",
      "Learning Rete :0.001\n",
      "40/40 [==============================] - 10s 243ms/step - loss: 0.0150 - acc: 0.9969 - val_loss: 0.8642 - val_acc: 0.7315\n",
      "Epoch 16/50\n",
      "Learning Rete :0.001\n",
      "40/40 [==============================] - 10s 243ms/step - loss: 0.0172 - acc: 0.9953 - val_loss: 0.8240 - val_acc: 0.7315\n",
      "Epoch 17/50\n",
      "Learning Rete :0.001\n",
      "40/40 [==============================] - 10s 247ms/step - loss: 0.0103 - acc: 0.9967 - val_loss: 0.7916 - val_acc: 0.7593\n",
      "Epoch 18/50\n",
      "Learning Rete :0.001\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 0.0311 - acc: 0.9941 - val_loss: 0.8237 - val_acc: 0.7500\n",
      "Epoch 19/50\n",
      "Learning Rete :0.001\n",
      "40/40 [==============================] - 10s 244ms/step - loss: 0.0164 - acc: 0.9945 - val_loss: 0.7994 - val_acc: 0.7315\n",
      "Epoch 20/50\n",
      "Learning Rete :0.001\n",
      "40/40 [==============================] - 10s 246ms/step - loss: 0.0177 - acc: 0.9943 - val_loss: 0.7603 - val_acc: 0.7222\n",
      "Epoch 21/50\n",
      "Learning Rete :0.00010000000000000002\n",
      "40/40 [==============================] - 10s 248ms/step - loss: 0.0157 - acc: 0.9975 - val_loss: 0.7500 - val_acc: 0.7315\n",
      "Epoch 22/50\n",
      "Learning Rete :0.00010000000000000002\n",
      "40/40 [==============================] - 10s 250ms/step - loss: 0.0113 - acc: 0.9977 - val_loss: 0.7460 - val_acc: 0.7222\n",
      "Epoch 23/50\n",
      "Learning Rete :0.00010000000000000002\n",
      "40/40 [==============================] - 10s 244ms/step - loss: 0.0072 - acc: 0.9984 - val_loss: 0.7439 - val_acc: 0.7315\n",
      "Epoch 24/50\n",
      "Learning Rete :0.00010000000000000002\n",
      "40/40 [==============================] - 10s 246ms/step - loss: 0.0073 - acc: 0.9977 - val_loss: 0.7397 - val_acc: 0.7315\n",
      "Epoch 25/50\n",
      "Learning Rete :0.00010000000000000002\n",
      "40/40 [==============================] - 10s 248ms/step - loss: 0.0114 - acc: 0.9984 - val_loss: 0.7418 - val_acc: 0.7315\n",
      "Epoch 26/50\n",
      "Learning Rete :0.00010000000000000002\n",
      "40/40 [==============================] - 10s 246ms/step - loss: 0.0089 - acc: 0.9984 - val_loss: 0.7409 - val_acc: 0.7315\n",
      "Epoch 27/50\n",
      "Learning Rete :0.00010000000000000002\n",
      "40/40 [==============================] - 10s 248ms/step - loss: 0.0163 - acc: 0.9941 - val_loss: 0.7491 - val_acc: 0.7315\n",
      "Epoch 28/50\n",
      "Learning Rete :0.00010000000000000002\n",
      "40/40 [==============================] - 10s 245ms/step - loss: 0.0127 - acc: 0.9977 - val_loss: 0.7460 - val_acc: 0.7315\n",
      "Epoch 29/50\n",
      "Learning Rete :0.00010000000000000002\n",
      "40/40 [==============================] - 10s 250ms/step - loss: 0.0123 - acc: 0.9969 - val_loss: 0.7449 - val_acc: 0.7315\n",
      "Epoch 30/50\n",
      "Learning Rete :0.00010000000000000002\n",
      "40/40 [==============================] - 10s 248ms/step - loss: 0.0166 - acc: 0.9931 - val_loss: 0.7338 - val_acc: 0.7315\n",
      "Epoch 31/50\n",
      "Learning Rete :1.0000000000000003e-05\n",
      "40/40 [==============================] - 10s 245ms/step - loss: 0.0071 - acc: 0.9984 - val_loss: 0.7268 - val_acc: 0.7315\n",
      "Epoch 32/50\n",
      "Learning Rete :1.0000000000000003e-05\n",
      "40/40 [==============================] - 10s 249ms/step - loss: 0.0106 - acc: 0.9969 - val_loss: 0.7288 - val_acc: 0.7315\n",
      "Epoch 33/50\n",
      "Learning Rete :1.0000000000000003e-05\n",
      "40/40 [==============================] - 10s 246ms/step - loss: 0.0093 - acc: 0.9984 - val_loss: 0.7311 - val_acc: 0.7315\n",
      "Epoch 34/50\n",
      "Learning Rete :1.0000000000000003e-05\n",
      "40/40 [==============================] - 10s 246ms/step - loss: 0.0126 - acc: 0.9984 - val_loss: 0.7320 - val_acc: 0.7315\n",
      "Epoch 35/50\n",
      "Learning Rete :1.0000000000000003e-05\n",
      "40/40 [==============================] - 10s 246ms/step - loss: 0.0167 - acc: 0.9935 - val_loss: 0.7352 - val_acc: 0.7315\n",
      "Epoch 36/50\n",
      "Learning Rete :1.0000000000000003e-05\n",
      "40/40 [==============================] - 10s 249ms/step - loss: 0.0091 - acc: 0.9975 - val_loss: 0.7350 - val_acc: 0.7315\n",
      "Epoch 37/50\n",
      "Learning Rete :1.0000000000000003e-05\n",
      "40/40 [==============================] - 10s 247ms/step - loss: 0.0195 - acc: 0.9939 - val_loss: 0.7381 - val_acc: 0.7315\n",
      "Epoch 38/50\n",
      "Learning Rete :1.0000000000000003e-05\n",
      "40/40 [==============================] - 10s 245ms/step - loss: 0.0091 - acc: 0.9969 - val_loss: 0.7368 - val_acc: 0.7315\n",
      "Epoch 39/50\n",
      "Learning Rete :1.0000000000000003e-05\n",
      "40/40 [==============================] - 10s 244ms/step - loss: 0.0167 - acc: 0.9953 - val_loss: 0.7381 - val_acc: 0.7315\n",
      "Epoch 40/50\n",
      "Learning Rete :1.0000000000000003e-05\n",
      "40/40 [==============================] - 10s 244ms/step - loss: 0.0103 - acc: 0.9953 - val_loss: 0.7338 - val_acc: 0.7315\n",
      "Epoch 41/50\n",
      "Learning Rete :1.0000000000000002e-06\n",
      "40/40 [==============================] - 10s 246ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.7350 - val_acc: 0.7315\n",
      "Epoch 00041: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nhistory = model.fit(X_train, y_train,\\n         batch_size=batch_size,\\n         epochs=epochs,\\n         validation_data=(X_test, y_test),\\n         shuffle=True,\\n         callbacks=[LearningRateScheduler(lr_schedule),\\n             ModelCheckpoint('model.h5', save_best_only=True)\\n         ])\\n         \""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lr_schedule(epoch):\n",
    "    print('Learning Rete :{}'.format(lr*(0.1**int(epoch/10))))\n",
    "    return lr*(0.1**int(epoch/10))\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "# earlystop\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "callbacks_list = [LearningRateScheduler(lr_schedule) ,checkpoint ,earlystop ]\n",
    "\n",
    "history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                            steps_per_epoch=X_train.shape[0] // (batch_size /3) ,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(X_test, y_test),\n",
    "                            #workers=2, cpu count\n",
    "                            callbacks=callbacks_list)\n",
    "'''\n",
    "history = model.fit(X_train, y_train,\n",
    "         batch_size=batch_size,\n",
    "         epochs=epochs,\n",
    "         validation_data=(X_test, y_test),\n",
    "         shuffle=True,\n",
    "         callbacks=[LearningRateScheduler(lr_schedule),\n",
    "             ModelCheckpoint('model.h5', save_best_only=True)\n",
    "         ])\n",
    "         '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 透過趨勢圖來觀察訓練與驗證的走向 (特別去觀察是否有\"過擬合(overfitting)\"的現象)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_train_history(history, train_metrics, val_metrics):\n",
    "    plt.plot(history.history.get(train_metrics),'-o')\n",
    "    plt.plot(history.history.get(val_metrics),'-o')\n",
    "    plt.ylabel(train_metrics)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend(['train', 'validation'])\n",
    "    \n",
    "plt.figure(figsize=(18,4))\n",
    "plt.subplot(1,2,1)\n",
    "plot_train_history(history, 'loss','val_loss')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plot_train_history(history, 'acc','val_acc')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 2s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7592592592592593"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)\n",
    "\n",
    "scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set (438, 224, 224, 3) (438, 5)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import PurePath # 處理不同作業系統file path的解析問題 (*nix vs windows)\n",
    "\n",
    "# 載入要驗證模型的數據\n",
    "def load_test_set(path):\n",
    "    pics, labels , img_name = [], [],[]\n",
    "    #reverse_dict = {v:k for k,v in map_characters.items()}\n",
    "    for pic in glob.glob(path+\"/\"+'*.png'):\n",
    "       \n",
    "        #char_name = \"_\".join(os.path.basename(pic).split('_')[:-1])\n",
    "        #if char_name in reverse_dict:\n",
    "            temp = cv2.imread(pic)  #轉灰階\n",
    "            temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "            #temp = cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY)\n",
    "            temp = cv2.resize(temp, (img_height,img_width))\n",
    "            #temp = np.expand_dims(temp, axis=2) #增加一個維度\n",
    "            temp = temp.astype('float32') / 255.\n",
    "            \n",
    "            pics.append(temp)\n",
    "        #    labels.append(reverse_dict[char_name])\n",
    "            labels.append(1) #預設都是1\n",
    "            #print(os.path.basename(pic).split('.jpg')[0])\n",
    "            img_name.append (os.path.basename(pic).split('.png')[0])\n",
    "            \n",
    "            \n",
    "    X_test = np.array(pics)\n",
    "    y_test = np.array(labels)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes) # 進行one-hot編碼\n",
    "    print(\"Test set\", X_test.shape, y_test.shape)\n",
    "    return X_test, y_test , img_name\n",
    "\n",
    "imgsPath = \"./testing_set\"\n",
    "\n",
    "#載入數據\n",
    "X_valtest, y_valtest , name_valtest = load_test_set(imgsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00C22FC0EA\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(X_valtest[5])\n",
    "print(name_valtest[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預測與比對\n",
    "from keras.models import load_model\n",
    "\n",
    "# 把訓練時val_loss最小的模型載入\n",
    "model = load_model('model-dtaug.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.2237442922374429\n"
     ]
    }
   ],
   "source": [
    "# 預測與比對\n",
    "#y_pred = model.predict_classes(X_valtest)\n",
    "\n",
    "y_pred_class = model.predict(X_valtest)\n",
    "y_perd_argmax = []  # 438\n",
    "\n",
    "for i in range(0 ,438):\n",
    "    y_perd_argmax.append(np.argmax(y_pred_class[i]))\n",
    "\n",
    "acc = np.sum(y_perd_argmax==np.argmax(y_valtest, axis=1))/np.size(y_perd_argmax)\n",
    "print(\"Test accuracy = {}\".format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_dict = dict(zip(name_valtest , y_perd_argmax))\n",
    "submission_tb = pd.DataFrame(list(submission_dict.items()), columns=['id','class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_tb.to_csv('./submit/submission_keras_3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
